{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a8f605d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48f44546",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "# í•´ë‹¹ í´ë˜ìŠ¤ê°€ ìš°ë¦¬ ëª¨ë¸ AODnet_MultiBranch ì‹¤ì œ ì´ë¦„ TBaodNet\n",
    "class AODnet_MultiBranch(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AODnet_MultiBranch, self).__init__()\n",
    "        print(\"[Model] Multi-Branch AODNet ì´ˆê¸°í™” ì¤‘ (3 ë…ë¦½ K ë³€ìˆ˜ ëª¨ë“œ)...\")\n",
    "\n",
    "        # ----- K_A Branch (ì˜ˆ: ì•ˆê°œ ì œê±°, Dehazing) -----\n",
    "        # K1 Branch êµ¬ì¡°ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€\n",
    "        self.k1_conv1 = nn.Conv2d(3, 3, kernel_size=1)\n",
    "        self.k1_conv2 = nn.Conv2d(3, 3, kernel_size=3, padding=1)\n",
    "        self.k1_conv3 = nn.Conv2d(6, 3, kernel_size=5, padding=2) # ì¶œë ¥ ì±„ë„: 3\n",
    "\n",
    "        # ----- K_B Branch (ì˜ˆ: ë¹—ì¤„ê¸° ì œê±°, Deraining) -----\n",
    "        # K2 Branch êµ¬ì¡°ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€\n",
    "        self.k2_conv1 = nn.Conv2d(3, 3, kernel_size=3, padding=1)\n",
    "        self.k2_conv2 = nn.Conv2d(3, 3, kernel_size=5, padding=2)\n",
    "        self.k2_conv3 = nn.Conv2d(6, 3, kernel_size=7, padding=3) # ì¶œë ¥ ì±„ë„: 3\n",
    "        \n",
    "        # ----- K_C Branch (ì˜ˆ: ë¬¼ë°©ìš¸ ì œê±°, Raindrop Removal) -----\n",
    "        # K3 Branch êµ¬ì¡°ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€\n",
    "        self.k3_conv1 = nn.Conv2d(3, 3, kernel_size=5, padding=2)\n",
    "        self.k3_conv2 = nn.Conv2d(3, 3, kernel_size=7, padding=3)\n",
    "        self.k3_conv3 = nn.Conv2d(6, 3, kernel_size=9, padding=4) # ì¶œë ¥ ì±„ë„: 3\n",
    "\n",
    "        # ğŸš¨ DBAODNet ë°©ì‹ ì ìš©ì„ ìœ„í•´ 'Fusion' ë ˆì´ì–´ ëŒ€ì‹  'ë…ë¦½ì ì¸ K ì¶œë ¥' ë ˆì´ì–´ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "        # K1, K2, K3 ê²°ê³¼ëŠ” ì´ë¯¸ ê° ë¸Œëœì¹˜ì˜ k_conv3ì—ì„œ 3ì±„ë„ë¡œ ë‚˜ì˜µë‹ˆë‹¤.\n",
    "        # ê¸°ì¡´ Fusion_convëŠ” K_finalì„ ë§Œë“¤ê¸° ìœ„í•´ ì¡´ì¬í–ˆìœ¼ë‚˜, ì´ì œ K1, K2, K3ê°€ ë…ë¦½ì ì¸ K_A, K_B, K_C ì—­í• ì„ í•©ë‹ˆë‹¤.\n",
    "        # ë”°ë¼ì„œ, ì¶”ê°€ Fusion ë ˆì´ì–´ ì—†ì´ K1, K2, K3ì˜ ê²°ê³¼(k1, k2, k3)ë¥¼ ê·¸ëŒ€ë¡œ K_A, K_B, K_Cë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "        \n",
    "        # self.fusion_conv = nn.Conv2d(9, 3, kernel_size=3, padding=1) # ğŸš¨ ì œê±°\n",
    "\n",
    "        print(\"[Model] Multi-Branch AODNet ì´ˆê¸°í™” ì™„ë£Œ\\n\")\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # --- K_A Branch (ì•ˆê°œ ì œê±°) ì—°ì‚° ---\n",
    "        x1_1 = F.relu(self.k1_conv1(x))\n",
    "        x1_2 = F.relu(self.k1_conv2(x1_1))\n",
    "        k1_cat = torch.cat((x1_1, x1_2), dim=1)\n",
    "        K_A = F.relu(self.k1_conv3(k1_cat)) # ğŸš¨ K_A ë³€ìˆ˜ (Dehazing ì •ë³´)\n",
    "\n",
    "        # --- K_B Branch (ë¹—ì¤„ê¸° ì œê±°) ì—°ì‚° ---\n",
    "        x2_1 = F.relu(self.k2_conv1(x))\n",
    "        x2_2 = F.relu(self.k2_conv2(x2_1))\n",
    "        k2_cat = torch.cat((x2_1, x2_2), dim=1)\n",
    "        K_B = F.relu(self.k2_conv3(k2_cat)) # ğŸš¨ K_B ë³€ìˆ˜ (Deraining ì •ë³´)\n",
    "\n",
    "        # --- K_C Branch (ë¬¼ë°©ìš¸ ì œê±°) ì—°ì‚° ---\n",
    "        x3_1 = F.relu(self.k3_conv1(x))\n",
    "        x3_2 = F.relu(self.k3_conv2(x3_1))\n",
    "        k3_cat = torch.cat((x3_1, x3_2), dim=1)\n",
    "        K_C = F.relu(self.k3_conv3(k3_cat)) # ğŸš¨ K_C ë³€ìˆ˜ (Raindrop ì •ë³´)\n",
    "\n",
    "        # ğŸš¨ DBAODNet ë°©ì‹ì˜ ìµœì¢… ë³µì› ê³µì‹ ì ìš© ğŸš¨\n",
    "        # DBAODNet í™•ì¥ ìœ ë„: J(x) = K_diff * I(x) - K_diff\n",
    "        # K_diff = K_A - K_B - K_C (K_Aë¥¼ ì£¼ ë³µì› í•­, K_B/K_Cë¥¼ ì°¨ê°/ì”ì—¬ í•­ìœ¼ë¡œ ê°€ì •)\n",
    "        \n",
    "        k_diff = K_A - K_B - K_C  # í†µí•© K_diff ê³„ì‚°\n",
    "        \n",
    "        output = k_diff * x - k_diff # ìµœì¢… ë³µì›ì‹ (ìƒìˆ˜í•­ ì—†ìŒ)\n",
    "        \n",
    "        return F.relu(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0cc2286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model] Multi-Branch AODNet ì´ˆê¸°í™” ì¤‘ (3 ë…ë¦½ K ë³€ìˆ˜ ëª¨ë“œ)...\n",
      "[Model] Multi-Branch AODNet ì´ˆê¸°í™” ì™„ë£Œ\n",
      "\n",
      "========== AODnet Summary ==========\n",
      "Layer: k1_conv1.weight,  Shape: torch.Size([3, 3, 1, 1])\n",
      "Layer: k1_conv1.bias,  Shape: torch.Size([3])\n",
      "Layer: k1_conv2.weight,  Shape: torch.Size([3, 3, 3, 3])\n",
      "Layer: k1_conv2.bias,  Shape: torch.Size([3])\n",
      "Layer: k1_conv3.weight,  Shape: torch.Size([3, 6, 5, 5])\n",
      "Layer: k1_conv3.bias,  Shape: torch.Size([3])\n",
      "Layer: k2_conv1.weight,  Shape: torch.Size([3, 3, 3, 3])\n",
      "Layer: k2_conv1.bias,  Shape: torch.Size([3])\n",
      "Layer: k2_conv2.weight,  Shape: torch.Size([3, 3, 5, 5])\n",
      "Layer: k2_conv2.bias,  Shape: torch.Size([3])\n",
      "Layer: k2_conv3.weight,  Shape: torch.Size([3, 6, 7, 7])\n",
      "Layer: k2_conv3.bias,  Shape: torch.Size([3])\n",
      "Layer: k3_conv1.weight,  Shape: torch.Size([3, 3, 5, 5])\n",
      "Layer: k3_conv1.bias,  Shape: torch.Size([3])\n",
      "Layer: k3_conv2.weight,  Shape: torch.Size([3, 3, 7, 7])\n",
      "Layer: k3_conv2.bias,  Shape: torch.Size([3])\n",
      "Layer: k3_conv3.weight,  Shape: torch.Size([3, 6, 9, 9])\n",
      "Layer: k3_conv3.bias,  Shape: torch.Size([3])\n",
      "\n",
      "Total trainable parameters: 3,879\n",
      "==============================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_model_summary(model, model_name):\n",
    "    \"\"\"ëª¨ë¸ì˜ íŒŒë¼ë¯¸í„° ì •ë³´ì™€ ì´ ê°œìˆ˜ë¥¼ ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    print(f\"========== {model_name} Summary ==========\")\n",
    "    \n",
    "    # ëª¨ë¸ì˜ ê° íŒŒë¼ë¯¸í„° ì´ë¦„ê³¼ í¬ê¸°(shape) ì¶œë ¥\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            print(f\"Layer: {name},  Shape: {param.shape}\")\n",
    "    \n",
    "    # ì „ì²´ íŒŒë¼ë¯¸í„° ê°œìˆ˜ ê³„ì‚° ë° ì¶œë ¥\n",
    "    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"\\nTotal trainable parameters: {total_params:,}\")\n",
    "    print(\"=\" * (len(model_name) + 24))\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "# 1. AODnet ëª¨ë¸ ê°ì²´ ìƒì„± ë° íŒŒë¼ë¯¸í„° í™•ì¸\n",
    "model = AODnet_MultiBranch()\n",
    "print_model_summary(model, \"AODnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a519c4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DehazeDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        \"\"\"\n",
    "        :param data_dir: train, test, val í´ë” ì¤‘ í•˜ë‚˜ì˜ ê²½ë¡œ (ì˜ˆ: 'dataset2_split/train')\n",
    "        :param transform: ì´ë¯¸ì§€ì— ì ìš©í•  torchvision.transforms\n",
    "        \"\"\"\n",
    "        self.gt_dir = os.path.join(data_dir, 'gt')\n",
    "        self.input_dir = os.path.join(data_dir, 'input')\n",
    "        self.transform = transform\n",
    "        \n",
    "        # input í´ë”ì˜ íŒŒì¼ ëª©ë¡ì„ ê¸°ì¤€ìœ¼ë¡œ ì‚¼ìŒ\n",
    "        self.image_files = os.listdir(self.input_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filename = self.image_files[idx]\n",
    "        \n",
    "        input_path = os.path.join(self.input_dir, filename)\n",
    "        gt_path = os.path.join(self.gt_dir, filename)\n",
    "        \n",
    "        # PIL ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•´ ì´ë¯¸ì§€ ì—´ê¸° (RGB í˜•ì‹ìœ¼ë¡œ ë³€í™˜)\n",
    "        input_image = Image.open(input_path).convert('RGB')\n",
    "        gt_image = Image.open(gt_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            input_image = self.transform(input_image)\n",
    "            gt_image = self.transform(gt_image)\n",
    "            \n",
    "        return input_image, gt_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "066c5128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# GPU ì‚¬ìš© ì„¤ì •\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# í•˜ì´í¼íŒŒë¼ë¯¸í„°\n",
    "LEARNING_RATE = 0.0001\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 100\n",
    "\n",
    "# ë°ì´í„°ì…‹ ê²½ë¡œ (split_dataset.py ì‹¤í–‰ í›„ ìƒì„±ëœ í´ë”)\n",
    "DATA_DIR = \"./dataset_split\"\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, 'train')\n",
    "VAL_DIR = os.path.join(DATA_DIR, 'val')\n",
    "\n",
    "# í•™ìŠµëœ ëª¨ë¸ ê°€ì¤‘ì¹˜ë¥¼ ì €ì¥í•  ê²½ë¡œ\n",
    "MODEL_SAVE_PATH = \"./pt/TBaodNet6\"\n",
    "os.makedirs(MODEL_SAVE_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a9ec114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í›ˆë ¨ ë°ì´í„°ì…‹ í¬ê¸°: 3543ê°œ\n",
      "ê²€ì¦ ë°ì´í„°ì…‹ í¬ê¸°: 507ê°œ\n",
      "ë°ì´í„°ì…‹ ë¡œë”© ì„±ê³µ!\n",
      "Input ì´ë¯¸ì§€ í…ì„œ ëª¨ì–‘: torch.Size([3, 240, 360])\n",
      "GT ì´ë¯¸ì§€ í…ì„œ ëª¨ì–‘: torch.Size([3, 240, 360])\n"
     ]
    }
   ],
   "source": [
    "# ì´ë¯¸ì§€ ë³€í™˜ ì„¤ì •\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((240, 360)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# í›ˆë ¨ ë°ì´í„°ì…‹ ë° ë°ì´í„° ë¡œë”\n",
    "train_dataset = DehazeDataset(data_dir=TRAIN_DIR, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "\n",
    "# ê²€ì¦ ë°ì´í„°ì…‹ ë° ë°ì´í„° ë¡œë”\n",
    "val_dataset = DehazeDataset(data_dir=VAL_DIR, transform=transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "print(f\"í›ˆë ¨ ë°ì´í„°ì…‹ í¬ê¸°: {len(train_dataset)}ê°œ\")\n",
    "print(f\"ê²€ì¦ ë°ì´í„°ì…‹ í¬ê¸°: {len(val_dataset)}ê°œ\")\n",
    "\n",
    "# ì…€ 5 ì‹¤í–‰ í›„ ì´ ì½”ë“œë¥¼ ì‹¤í–‰í•´ë³´ì„¸ìš”\n",
    "try:\n",
    "    input_img, gt_img = train_dataset[0]\n",
    "    print(\"ë°ì´í„°ì…‹ ë¡œë”© ì„±ê³µ!\")\n",
    "    print(\"Input ì´ë¯¸ì§€ í…ì„œ ëª¨ì–‘:\", input_img.shape)\n",
    "    print(\"GT ì´ë¯¸ì§€ í…ì„œ ëª¨ì–‘:\", gt_img.shape)\n",
    "except Exception as e:\n",
    "    print(\"ë°ì´í„°ì…‹ ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1016936e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model] Multi-Branch AODNet ì´ˆê¸°í™” ì¤‘ (3 ë…ë¦½ K ë³€ìˆ˜ ëª¨ë“œ)...\n",
      "[Model] Multi-Branch AODNet ì´ˆê¸°í™” ì™„ë£Œ\n",
      "\n",
      "Model: AODnet_MultiBranch\n"
     ]
    }
   ],
   "source": [
    "# ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ë° GPUë¡œ ì´ë™\n",
    "# model = AODnet().to(DEVICE) # ê¸°ë³¸ ëª¨ë¸ì„ ì‚¬ìš©í•˜ë ¤ë©´ ì´ ì¤„ì˜ ì£¼ì„ì„ í•´ì œ\n",
    "model = AODnet_MultiBranch().to(DEVICE) # PONO ëª¨ë¸ ì‚¬ìš©\n",
    "print(\"Model:\", model.__class__.__name__)\n",
    "\n",
    "# ì†ì‹¤ í•¨ìˆ˜ (Loss Function) - ì´ë¯¸ì§€ ë³µì›ì—ëŠ” MSE Lossê°€ ì¼ë°˜ì ìœ¼ë¡œ ì‚¬ìš©ë¨\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# ì˜µí‹°ë§ˆì´ì € (Optimizer) - Adamì´ ì•ˆì •ì ì´ê³  ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì„\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f98b724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== ëª¨ë¸ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤ =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:51<00:00,  4.34it/s, loss=0.0806]\n",
      "Epoch 1/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:04<00:00,  7.32it/s, loss=0.165] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Train Loss: 0.153250, Val Loss: 0.117983\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_1.pth (Val Loss: 0.117983) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:43<00:00,  5.05it/s, loss=0.123] \n",
      "Epoch 2/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.20it/s, loss=0.144] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/100], Train Loss: 0.106625, Val Loss: 0.103987\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_2.pth (Val Loss: 0.103987) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:44<00:00,  5.02it/s, loss=0.129] \n",
      "Epoch 3/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.26it/s, loss=0.132] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/100], Train Loss: 0.097591, Val Loss: 0.096911\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_3.pth (Val Loss: 0.096911) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:43<00:00,  5.05it/s, loss=0.132] \n",
      "Epoch 4/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.15it/s, loss=0.123] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/100], Train Loss: 0.091543, Val Loss: 0.090886\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_4.pth (Val Loss: 0.090886) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:44<00:00,  5.01it/s, loss=0.0847]\n",
      "Epoch 5/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.23it/s, loss=0.118] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/100], Train Loss: 0.085832, Val Loss: 0.086753\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_5.pth (Val Loss: 0.086753) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:44<00:00,  5.04it/s, loss=0.0829]\n",
      "Epoch 6/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.21it/s, loss=0.112] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/100], Train Loss: 0.082236, Val Loss: 0.083466\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_6.pth (Val Loss: 0.083466) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:44<00:00,  5.04it/s, loss=0.128] \n",
      "Epoch 7/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.22it/s, loss=0.11]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/100], Train Loss: 0.080039, Val Loss: 0.081578\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_7.pth (Val Loss: 0.081578) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:44<00:00,  5.02it/s, loss=0.143] \n",
      "Epoch 8/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.13it/s, loss=0.105] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/100], Train Loss: 0.077844, Val Loss: 0.079507\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_8.pth (Val Loss: 0.079507) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:44<00:00,  5.04it/s, loss=0.06]  \n",
      "Epoch 9/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.21it/s, loss=0.103] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/100], Train Loss: 0.076163, Val Loss: 0.077877\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_9.pth (Val Loss: 0.077877) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:44<00:00,  5.04it/s, loss=0.067] \n",
      "Epoch 10/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.25it/s, loss=0.102] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Train Loss: 0.074649, Val Loss: 0.076812\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_10.pth (Val Loss: 0.076812) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:44<00:00,  5.04it/s, loss=0.0713]\n",
      "Epoch 11/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.24it/s, loss=0.097] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/100], Train Loss: 0.073473, Val Loss: 0.075608\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_11.pth (Val Loss: 0.075608) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:44<00:00,  5.03it/s, loss=0.0884]\n",
      "Epoch 12/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.21it/s, loss=0.0954]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/100], Train Loss: 0.072415, Val Loss: 0.074636\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_12.pth (Val Loss: 0.074636) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:43<00:00,  5.05it/s, loss=0.059] \n",
      "Epoch 13/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.32it/s, loss=0.0936]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/100], Train Loss: 0.071614, Val Loss: 0.073910\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_13.pth (Val Loss: 0.073910) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:43<00:00,  5.06it/s, loss=0.0486]\n",
      "Epoch 14/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.15it/s, loss=0.0934]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/100], Train Loss: 0.070773, Val Loss: 0.073083\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_14.pth (Val Loss: 0.073083) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:43<00:00,  5.05it/s, loss=0.0658]\n",
      "Epoch 15/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.21it/s, loss=0.0933]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/100], Train Loss: 0.070298, Val Loss: 0.072698\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_15.pth (Val Loss: 0.072698) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:43<00:00,  5.06it/s, loss=0.056] \n",
      "Epoch 16/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.23it/s, loss=0.0872]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/100], Train Loss: 0.069596, Val Loss: 0.072803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:43<00:00,  5.05it/s, loss=0.0675]\n",
      "Epoch 17/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.25it/s, loss=0.0915]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/100], Train Loss: 0.068852, Val Loss: 0.071738\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_17.pth (Val Loss: 0.071738) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:43<00:00,  5.05it/s, loss=0.0987]\n",
      "Epoch 18/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.15it/s, loss=0.0905]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/100], Train Loss: 0.068748, Val Loss: 0.071317\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_18.pth (Val Loss: 0.071317) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:43<00:00,  5.05it/s, loss=0.0682]\n",
      "Epoch 19/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.28it/s, loss=0.0873]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/100], Train Loss: 0.067813, Val Loss: 0.070289\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_19.pth (Val Loss: 0.070289) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:44<00:00,  5.04it/s, loss=0.0804]\n",
      "Epoch 20/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.29it/s, loss=0.0834]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/100], Train Loss: 0.067471, Val Loss: 0.069628\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_20.pth (Val Loss: 0.069628) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:44<00:00,  5.02it/s, loss=0.0576]\n",
      "Epoch 21/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.25it/s, loss=0.0821]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/100], Train Loss: 0.066918, Val Loss: 0.069300\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_21.pth (Val Loss: 0.069300) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:44<00:00,  5.04it/s, loss=0.0468]\n",
      "Epoch 22/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.19it/s, loss=0.0803]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/100], Train Loss: 0.066419, Val Loss: 0.069007\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_22.pth (Val Loss: 0.069007) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:43<00:00,  5.05it/s, loss=0.104] \n",
      "Epoch 23/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.27it/s, loss=0.083] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/100], Train Loss: 0.066244, Val Loss: 0.068413\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_23.pth (Val Loss: 0.068413) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:43<00:00,  5.05it/s, loss=0.0563]\n",
      "Epoch 24/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.20it/s, loss=0.0783]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/100], Train Loss: 0.065565, Val Loss: 0.068402\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_24.pth (Val Loss: 0.068402) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:43<00:00,  5.05it/s, loss=0.0506]\n",
      "Epoch 25/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.11it/s, loss=0.0776]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/100], Train Loss: 0.065223, Val Loss: 0.067584\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_25.pth (Val Loss: 0.067584) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:44<00:00,  5.04it/s, loss=0.0682]\n",
      "Epoch 26/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.28it/s, loss=0.0801]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/100], Train Loss: 0.064952, Val Loss: 0.067261\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_26.pth (Val Loss: 0.067261) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:43<00:00,  5.05it/s, loss=0.0629]\n",
      "Epoch 27/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.25it/s, loss=0.077] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/100], Train Loss: 0.064706, Val Loss: 0.066882\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_27.pth (Val Loss: 0.066882) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:43<00:00,  5.05it/s, loss=0.061] \n",
      "Epoch 28/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.27it/s, loss=0.0803]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/100], Train Loss: 0.064316, Val Loss: 0.067231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:44<00:00,  5.02it/s, loss=0.0488]\n",
      "Epoch 29/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  8.99it/s, loss=0.0777]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/100], Train Loss: 0.063954, Val Loss: 0.066409\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_29.pth (Val Loss: 0.066409) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:44<00:00,  5.00it/s, loss=0.0471]\n",
      "Epoch 30/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.17it/s, loss=0.0748]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/100], Train Loss: 0.063596, Val Loss: 0.065965\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_30.pth (Val Loss: 0.065965) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:44<00:00,  5.04it/s, loss=0.053] \n",
      "Epoch 31/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.22it/s, loss=0.0718]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/100], Train Loss: 0.063390, Val Loss: 0.067042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:43<00:00,  5.05it/s, loss=0.0566]\n",
      "Epoch 32/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.08it/s, loss=0.0712]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/100], Train Loss: 0.063246, Val Loss: 0.065723\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_32.pth (Val Loss: 0.065723) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:43<00:00,  5.05it/s, loss=0.0719]\n",
      "Epoch 33/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.26it/s, loss=0.0734]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/100], Train Loss: 0.062879, Val Loss: 0.064946\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_33.pth (Val Loss: 0.064946) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:43<00:00,  5.05it/s, loss=0.0533]\n",
      "Epoch 34/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.24it/s, loss=0.0732]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/100], Train Loss: 0.062562, Val Loss: 0.064669\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_34.pth (Val Loss: 0.064669) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:43<00:00,  5.06it/s, loss=0.0908]\n",
      "Epoch 35/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.20it/s, loss=0.0691]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/100], Train Loss: 0.062326, Val Loss: 0.065239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:43<00:00,  5.05it/s, loss=0.0385]\n",
      "Epoch 36/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.22it/s, loss=0.0731]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/100], Train Loss: 0.062077, Val Loss: 0.064399\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_36.pth (Val Loss: 0.064399) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:43<00:00,  5.05it/s, loss=0.0594]\n",
      "Epoch 37/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.08it/s, loss=0.0693]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/100], Train Loss: 0.061806, Val Loss: 0.063864\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_37.pth (Val Loss: 0.063864) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:44<00:00,  5.04it/s, loss=0.0494]\n",
      "Epoch 38/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.22it/s, loss=0.0723]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/100], Train Loss: 0.061545, Val Loss: 0.063875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:44<00:00,  5.02it/s, loss=0.0875]\n",
      "Epoch 39/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.23it/s, loss=0.0684]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/100], Train Loss: 0.061303, Val Loss: 0.063633\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_39.pth (Val Loss: 0.063633) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:43<00:00,  5.05it/s, loss=0.0537]\n",
      "Epoch 40/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.28it/s, loss=0.068] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/100], Train Loss: 0.061084, Val Loss: 0.063359\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_40.pth (Val Loss: 0.063359) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:43<00:00,  5.05it/s, loss=0.0427]\n",
      "Epoch 41/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.19it/s, loss=0.0736]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/100], Train Loss: 0.060820, Val Loss: 0.064219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:45<00:00,  4.83it/s, loss=0.0584]\n",
      "Epoch 42/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.09it/s, loss=0.0666]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/100], Train Loss: 0.060693, Val Loss: 0.062799\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_42.pth (Val Loss: 0.062799) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:44<00:00,  4.98it/s, loss=0.0534]\n",
      "Epoch 43/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.40it/s, loss=0.0683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/100], Train Loss: 0.060405, Val Loss: 0.062467\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_43.pth (Val Loss: 0.062467) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:44<00:00,  4.98it/s, loss=0.0446]\n",
      "Epoch 44/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.42it/s, loss=0.0693]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/100], Train Loss: 0.060343, Val Loss: 0.062808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:44<00:00,  5.02it/s, loss=0.0852]\n",
      "Epoch 45/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.40it/s, loss=0.0669]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/100], Train Loss: 0.060212, Val Loss: 0.062171\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_45.pth (Val Loss: 0.062171) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:44<00:00,  5.03it/s, loss=0.0536]\n",
      "Epoch 46/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.43it/s, loss=0.0666]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/100], Train Loss: 0.060158, Val Loss: 0.062001\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_46.pth (Val Loss: 0.062001) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:44<00:00,  5.03it/s, loss=0.0892]\n",
      "Epoch 47/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.29it/s, loss=0.0665]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/100], Train Loss: 0.059745, Val Loss: 0.061723\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_47.pth (Val Loss: 0.061723) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:44<00:00,  5.02it/s, loss=0.0384]\n",
      "Epoch 48/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.42it/s, loss=0.0655]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/100], Train Loss: 0.059375, Val Loss: 0.061514\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_48.pth (Val Loss: 0.061514) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:44<00:00,  5.02it/s, loss=0.0485]\n",
      "Epoch 49/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.51it/s, loss=0.0651]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/100], Train Loss: 0.059315, Val Loss: 0.061455\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_49.pth (Val Loss: 0.061455) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:44<00:00,  5.04it/s, loss=0.0619]\n",
      "Epoch 50/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.44it/s, loss=0.0685]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/100], Train Loss: 0.059345, Val Loss: 0.061949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:43<00:00,  5.05it/s, loss=0.0613]\n",
      "Epoch 51/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.55it/s, loss=0.0658]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [51/100], Train Loss: 0.059166, Val Loss: 0.061169\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_51.pth (Val Loss: 0.061169) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:44<00:00,  5.04it/s, loss=0.0649]\n",
      "Epoch 52/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.36it/s, loss=0.0662]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52/100], Train Loss: 0.058817, Val Loss: 0.061409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:44<00:00,  5.01it/s, loss=0.0471]\n",
      "Epoch 53/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.35it/s, loss=0.0631]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [53/100], Train Loss: 0.058609, Val Loss: 0.060648\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_53.pth (Val Loss: 0.060648) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:44<00:00,  5.02it/s, loss=0.0688]\n",
      "Epoch 54/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.48it/s, loss=0.0622]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [54/100], Train Loss: 0.058337, Val Loss: 0.060835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:43<00:00,  5.05it/s, loss=0.0345]\n",
      "Epoch 55/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.46it/s, loss=0.0625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [55/100], Train Loss: 0.058288, Val Loss: 0.060295\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_55.pth (Val Loss: 0.060295) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:44<00:00,  5.02it/s, loss=0.08]  \n",
      "Epoch 56/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.48it/s, loss=0.0639]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [56/100], Train Loss: 0.058133, Val Loss: 0.060275\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_56.pth (Val Loss: 0.060275) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:44<00:00,  5.01it/s, loss=0.0675]\n",
      "Epoch 57/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.43it/s, loss=0.0637]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [57/100], Train Loss: 0.057748, Val Loss: 0.060175\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_57.pth (Val Loss: 0.060175) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:44<00:00,  5.03it/s, loss=0.0462]\n",
      "Epoch 58/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.47it/s, loss=0.0608]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [58/100], Train Loss: 0.057628, Val Loss: 0.059585\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_58.pth (Val Loss: 0.059585) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:44<00:00,  5.04it/s, loss=0.0332]\n",
      "Epoch 59/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.38it/s, loss=0.0602]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [59/100], Train Loss: 0.057379, Val Loss: 0.059800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:44<00:00,  5.04it/s, loss=0.0534]\n",
      "Epoch 60/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.41it/s, loss=0.0624]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60/100], Train Loss: 0.057414, Val Loss: 0.059450\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_60.pth (Val Loss: 0.059450) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:43<00:00,  5.05it/s, loss=0.0477]\n",
      "Epoch 61/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.47it/s, loss=0.0592]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [61/100], Train Loss: 0.057455, Val Loss: 0.059763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:44<00:00,  5.01it/s, loss=0.0421]\n",
      "Epoch 62/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.45it/s, loss=0.0592]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [62/100], Train Loss: 0.056999, Val Loss: 0.059725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:44<00:00,  5.02it/s, loss=0.0432]\n",
      "Epoch 63/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.52it/s, loss=0.059] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [63/100], Train Loss: 0.056905, Val Loss: 0.059399\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_63.pth (Val Loss: 0.059399) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:44<00:00,  5.03it/s, loss=0.0586]\n",
      "Epoch 64/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.50it/s, loss=0.0603]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [64/100], Train Loss: 0.056650, Val Loss: 0.058922\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_64.pth (Val Loss: 0.058922) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:44<00:00,  5.02it/s, loss=0.0563]\n",
      "Epoch 65/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.40it/s, loss=0.0608]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [65/100], Train Loss: 0.056490, Val Loss: 0.058623\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_65.pth (Val Loss: 0.058623) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:44<00:00,  5.01it/s, loss=0.0393]\n",
      "Epoch 66/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.43it/s, loss=0.0585]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [66/100], Train Loss: 0.056363, Val Loss: 0.058581\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_66.pth (Val Loss: 0.058581) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:44<00:00,  5.03it/s, loss=0.0477]\n",
      "Epoch 67/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.48it/s, loss=0.0601]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [67/100], Train Loss: 0.056379, Val Loss: 0.058209\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_67.pth (Val Loss: 0.058209) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:44<00:00,  5.04it/s, loss=0.0364]\n",
      "Epoch 68/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.40it/s, loss=0.0584]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [68/100], Train Loss: 0.056237, Val Loss: 0.058498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:44<00:00,  5.04it/s, loss=0.0509]\n",
      "Epoch 69/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.45it/s, loss=0.058] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [69/100], Train Loss: 0.055928, Val Loss: 0.058248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:44<00:00,  5.04it/s, loss=0.0394]\n",
      "Epoch 70/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.39it/s, loss=0.0613]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [70/100], Train Loss: 0.055710, Val Loss: 0.058577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:44<00:00,  5.01it/s, loss=0.041] \n",
      "Epoch 71/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.38it/s, loss=0.06]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [71/100], Train Loss: 0.055735, Val Loss: 0.057909\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_71.pth (Val Loss: 0.057909) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:44<00:00,  4.98it/s, loss=0.0506]\n",
      "Epoch 72/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  8.93it/s, loss=0.0589]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [72/100], Train Loss: 0.055694, Val Loss: 0.057618\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_72.pth (Val Loss: 0.057618) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:43<00:00,  5.05it/s, loss=0.0385]\n",
      "Epoch 73/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.17it/s, loss=0.0585]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [73/100], Train Loss: 0.055575, Val Loss: 0.057434\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_73.pth (Val Loss: 0.057434) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:44<00:00,  5.04it/s, loss=0.0535]\n",
      "Epoch 74/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.19it/s, loss=0.0592]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [74/100], Train Loss: 0.055529, Val Loss: 0.057442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:44<00:00,  5.03it/s, loss=0.0633]\n",
      "Epoch 75/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.18it/s, loss=0.0629]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [75/100], Train Loss: 0.055400, Val Loss: 0.058687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:44<00:00,  5.04it/s, loss=0.0757]\n",
      "Epoch 76/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.19it/s, loss=0.0577]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [76/100], Train Loss: 0.055162, Val Loss: 0.057061\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_76.pth (Val Loss: 0.057061) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:44<00:00,  5.02it/s, loss=0.0369]\n",
      "Epoch 77/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.12it/s, loss=0.0581]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [77/100], Train Loss: 0.055063, Val Loss: 0.056998\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_77.pth (Val Loss: 0.056998) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:44<00:00,  5.03it/s, loss=0.0376]\n",
      "Epoch 78/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.18it/s, loss=0.0619]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [78/100], Train Loss: 0.054909, Val Loss: 0.058125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:43<00:00,  5.05it/s, loss=0.0521]\n",
      "Epoch 79/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.21it/s, loss=0.0563]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [79/100], Train Loss: 0.054819, Val Loss: 0.056905\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_79.pth (Val Loss: 0.056905) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:43<00:00,  5.12it/s, loss=0.0658]\n",
      "Epoch 80/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.74it/s, loss=0.0573]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [80/100], Train Loss: 0.054854, Val Loss: 0.056623\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_80.pth (Val Loss: 0.056623) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:45<00:00,  4.92it/s, loss=0.0563]\n",
      "Epoch 81/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.11it/s, loss=0.0585]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [81/100], Train Loss: 0.054680, Val Loss: 0.056767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 82/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:45<00:00,  4.90it/s, loss=0.0574]\n",
      "Epoch 82/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.02it/s, loss=0.0563]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [82/100], Train Loss: 0.054385, Val Loss: 0.056648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 83/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:44<00:00,  4.98it/s, loss=0.0585]\n",
      "Epoch 83/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.39it/s, loss=0.0579]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [83/100], Train Loss: 0.054352, Val Loss: 0.056755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 84/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:43<00:00,  5.07it/s, loss=0.0747]\n",
      "Epoch 84/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.39it/s, loss=0.0559]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [84/100], Train Loss: 0.054214, Val Loss: 0.056235\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_84.pth (Val Loss: 0.056235) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 85/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:43<00:00,  5.08it/s, loss=0.0527]\n",
      "Epoch 85/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.46it/s, loss=0.0557]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [85/100], Train Loss: 0.054142, Val Loss: 0.056042\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_85.pth (Val Loss: 0.056042) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 86/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:44<00:00,  4.98it/s, loss=0.0301]\n",
      "Epoch 86/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.29it/s, loss=0.0559]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [86/100], Train Loss: 0.054110, Val Loss: 0.058152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 87/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:44<00:00,  5.04it/s, loss=0.031] \n",
      "Epoch 87/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.17it/s, loss=0.0565]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [87/100], Train Loss: 0.053986, Val Loss: 0.055934\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_87.pth (Val Loss: 0.055934) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 88/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:44<00:00,  5.05it/s, loss=0.0622]\n",
      "Epoch 88/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.44it/s, loss=0.0581]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [88/100], Train Loss: 0.053851, Val Loss: 0.056341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:43<00:00,  5.09it/s, loss=0.0274]\n",
      "Epoch 89/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.53it/s, loss=0.0548]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [89/100], Train Loss: 0.053524, Val Loss: 0.055846\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_89.pth (Val Loss: 0.055846) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 90/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:43<00:00,  5.09it/s, loss=0.0649]\n",
      "Epoch 90/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.48it/s, loss=0.0573]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [90/100], Train Loss: 0.053708, Val Loss: 0.055870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 91/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:43<00:00,  5.10it/s, loss=0.0622]\n",
      "Epoch 91/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.49it/s, loss=0.055] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [91/100], Train Loss: 0.053574, Val Loss: 0.055700\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_91.pth (Val Loss: 0.055700) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 92/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:43<00:00,  5.07it/s, loss=0.0562]\n",
      "Epoch 92/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.55it/s, loss=0.0559]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [92/100], Train Loss: 0.053544, Val Loss: 0.055519\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_92.pth (Val Loss: 0.055519) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 93/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:43<00:00,  5.09it/s, loss=0.0261]\n",
      "Epoch 93/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.57it/s, loss=0.056] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [93/100], Train Loss: 0.053279, Val Loss: 0.055452\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_93.pth (Val Loss: 0.055452) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 94/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:43<00:00,  5.08it/s, loss=0.0545]\n",
      "Epoch 94/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.49it/s, loss=0.054] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [94/100], Train Loss: 0.053229, Val Loss: 0.055620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 95/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:43<00:00,  5.09it/s, loss=0.0348]\n",
      "Epoch 95/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.49it/s, loss=0.0559]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [95/100], Train Loss: 0.053433, Val Loss: 0.055263\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_95.pth (Val Loss: 0.055263) *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 96/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:43<00:00,  5.06it/s, loss=0.0307]\n",
      "Epoch 96/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.21it/s, loss=0.0536]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [96/100], Train Loss: 0.053103, Val Loss: 0.056826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 97/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:44<00:00,  5.01it/s, loss=0.0389]\n",
      "Epoch 97/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.50it/s, loss=0.056] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [97/100], Train Loss: 0.052963, Val Loss: 0.055392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 98/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:44<00:00,  5.02it/s, loss=0.0594]\n",
      "Epoch 98/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.52it/s, loss=0.0589]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [98/100], Train Loss: 0.053085, Val Loss: 0.056054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:43<00:00,  5.09it/s, loss=0.0393]\n",
      "Epoch 99/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.49it/s, loss=0.0548]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [99/100], Train Loss: 0.052812, Val Loss: 0.055423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [00:44<00:00,  5.03it/s, loss=0.0711]\n",
      "Epoch 100/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.05it/s, loss=0.0555]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Train Loss: 0.052810, Val Loss: 0.054968\n",
      "***** Best model saved to ./pt/TBaodNet6\\best_model_epoch_100.pth (Val Loss: 0.054968) *****\n",
      "\n",
      "\n",
      "===== ëª¨ë“  í•™ìŠµì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ê° ì—í­ì˜ ì†ì‹¤ ê°’ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
    "train_loss_history = [] # <<< ì¶”ê°€\n",
    "val_loss_history = []   # <<< ì¶”ê°€\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "print(\"\\n===== ëª¨ë¸ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤ =====\")\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # --- í›ˆë ¨ ë‹¨ê³„ ---\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    train_iterator = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Train]\")\n",
    "    for hazy_images, clean_images in train_iterator:\n",
    "        hazy_images = hazy_images.to(DEVICE)\n",
    "        clean_images = clean_images.to(DEVICE)\n",
    "        \n",
    "        outputs = model(hazy_images)\n",
    "        loss = criterion(outputs, clean_images)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        train_iterator.set_postfix({'loss': loss.item()})\n",
    "        \n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    train_loss_history.append(avg_train_loss) # <<< ì¶”ê°€\n",
    "\n",
    "    # --- ê²€ì¦ ë‹¨ê³„ ---\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        val_iterator = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Val]\")\n",
    "        for hazy_images, clean_images in val_iterator:\n",
    "            hazy_images = hazy_images.to(DEVICE)\n",
    "            clean_images = clean_images.to(DEVICE)\n",
    "            \n",
    "            outputs = model(hazy_images)\n",
    "            loss = criterion(outputs, clean_images)\n",
    "            val_loss += loss.item()\n",
    "            val_iterator.set_postfix({'loss': loss.item()})\n",
    "            \n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_loss_history.append(avg_val_loss) # <<< ì¶”ê°€\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}], Train Loss: {avg_train_loss:.6f}, Val Loss: {avg_val_loss:.6f}\")\n",
    "    \n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        save_file = os.path.join(MODEL_SAVE_PATH, f\"best_model_epoch_{epoch+1}.pth\")\n",
    "        torch.save(model.state_dict(), save_file)\n",
    "        print(f\"***** Best model saved to {save_file} (Val Loss: {best_val_loss:.6f}) *****\\n\")\n",
    "\n",
    "print(\"\\n===== ëª¨ë“  í•™ìŠµì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! =====\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d13406a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ê·¸ë˜í”„ í¬ê¸° ì„¤ì •\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# í›ˆë ¨ ì†ì‹¤ê³¼ ê²€ì¦ ì†ì‹¤ ê·¸ë˜í”„ ê·¸ë¦¬ê¸°\n",
    "plt.plot(range(1, NUM_EPOCHS + 1), train_loss_history, label='Train Loss', color='blue')\n",
    "plt.plot(range(1, NUM_EPOCHS + 1), val_loss_history, label='Validation Loss', color='red')\n",
    "\n",
    "# ê·¸ë˜í”„ ì œëª© ë° ì¶• ë ˆì´ë¸” ì„¤ì •\n",
    "plt.title('Training & Validation Loss Over Epochs', fontsize=16)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "\n",
    "# ë²”ë¡€ í‘œì‹œ\n",
    "plt.legend()\n",
    "\n",
    "# ê·¸ë¦¬ë“œ í‘œì‹œ\n",
    "plt.grid(True)\n",
    "\n",
    "# ê·¸ë˜í”„ ë³´ì—¬ì£¼ê¸°\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "089b36bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model] Multi-Branch AODNet ì´ˆê¸°í™” ì¤‘ (3 ë…ë¦½ K ë³€ìˆ˜ ëª¨ë“œ)...\n",
      "[Model] Multi-Branch AODNet ì´ˆê¸°í™” ì™„ë£Œ\n",
      "\n",
      "\n",
      "===== 'pt/TBaodNet6/best_model_epoch_100.pth' ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ì‹œì‘ =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 127/127 [00:20<00:00,  6.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== í‰ê°€ ì™„ë£Œ =====\n",
      "í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ í‰ê·  PSNR: 13.6318 dB\n",
      "í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ í‰ê·  SSIM: 0.4738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ìƒˆë¡œìš´ ì…€\n",
    "\n",
    "import numpy as np\n",
    "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
    "\n",
    "# --- ì„¤ì • (â˜…â˜…â˜… ì‚¬ìš© ì „ ê¼­ ìˆ˜ì •í•´ì£¼ì„¸ìš” â˜…â˜…â˜…) ---\n",
    "# 1. í‰ê°€ì— ì‚¬ìš©í•  í…ŒìŠ¤íŠ¸ì…‹ í´ë” ê²½ë¡œ\n",
    "TEST_DIR = os.path.join(DATA_DIR, 'test')\n",
    "\n",
    "# 2. ë¶ˆëŸ¬ì˜¬ í•™ìŠµëœ ëª¨ë¸ ê°€ì¤‘ì¹˜ íŒŒì¼ì˜ ê²½ë¡œ\n",
    "# 'trained_models' í´ë” ì•ˆì— ì €ì¥ëœ .pth íŒŒì¼ ì¤‘ ê°€ì¥ ì„±ëŠ¥ì´ ì¢‹ì•˜ë˜(best) ëª¨ë¸ì˜ ê²½ë¡œë¥¼ ì§€ì •í•©ë‹ˆë‹¤.\n",
    "MODEL_WEIGHTS_PATH = \"pt/TBaodNet6/best_model_epoch_100.pth\" # XX ë¶€ë¶„ì€ ì‹¤ì œ íŒŒì¼ ìˆ«ìë¡œ ë³€ê²½\n",
    "# --------------------------------------------------\n",
    "\n",
    "# ëª¨ë¸ êµ¬ì¡° ë¡œë“œ ë° ê°€ì¤‘ì¹˜ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "evaluation_model = AODnet_MultiBranch().to(DEVICE)\n",
    "evaluation_model.load_state_dict(torch.load(MODEL_WEIGHTS_PATH, map_location=DEVICE))\n",
    "evaluation_model.eval() # ëª¨ë¸ì„ ë°˜ë“œì‹œ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •!\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë” ì¤€ë¹„\n",
    "test_dataset = DehazeDataset(data_dir=TEST_DIR, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=0) # num_workers=0ìœ¼ë¡œ ì„¤ì •\n",
    "\n",
    "# ì ìˆ˜ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”\n",
    "psnr_scores = []\n",
    "ssim_scores = []\n",
    "\n",
    "print(f\"\\n===== '{MODEL_WEIGHTS_PATH}' ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ì‹œì‘ =====\")\n",
    "\n",
    "# í‰ê°€ ë£¨í”„\n",
    "with torch.no_grad(): # ê¸°ìš¸ê¸° ê³„ì‚° ë¹„í™œì„±í™”\n",
    "    for hazy_images, clean_images in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "        hazy_images = hazy_images.to(DEVICE)\n",
    "        \n",
    "        # ëª¨ë¸ ì¶”ë¡ \n",
    "        outputs = evaluation_model(hazy_images)\n",
    "        \n",
    "        # GPU í…ì„œë¥¼ CPUì˜ Numpy ë°°ì—´ë¡œ ë³€í™˜ (skimage ê³„ì‚°ìš©)\n",
    "        # (B, C, H, W) -> (B, H, W, C) í˜•íƒœë¡œ ë³€ê²½ ë° 0-255 ë²”ìœ„ì˜ ì •ìˆ˜í˜•ìœ¼ë¡œ ë³€í™˜\n",
    "        outputs_np = outputs.cpu().permute(0, 2, 3, 1).numpy() * 255\n",
    "        clean_images_np = clean_images.cpu().permute(0, 2, 3, 1).numpy() * 255\n",
    "        \n",
    "        outputs_np = outputs_np.astype(np.uint8)\n",
    "        clean_images_np = clean_images_np.astype(np.uint8)\n",
    "        \n",
    "        # ë°°ì¹˜ ë‚´ì˜ ê° ì´ë¯¸ì§€ì— ëŒ€í•´ ì ìˆ˜ ê³„ì‚°\n",
    "        for i in range(clean_images_np.shape[0]):\n",
    "            gt_image = clean_images_np[i]\n",
    "            pred_image = outputs_np[i]\n",
    "            \n",
    "            # PSNR ê³„ì‚°\n",
    "            psnr = peak_signal_noise_ratio(gt_image, pred_image, data_range=255)\n",
    "            psnr_scores.append(psnr)\n",
    "            \n",
    "            # SSIM ê³„ì‚°\n",
    "            # channel_axis=-1 ì€ ì»¬ëŸ¬ ì´ë¯¸ì§€(RGB)ì˜ ì±„ë„ ì¶•ì„ ì§€ì •í•´ì¤ë‹ˆë‹¤.\n",
    "            ssim = structural_similarity(gt_image, pred_image, channel_axis=-1, data_range=255)\n",
    "            ssim_scores.append(ssim)\n",
    "\n",
    "# í‰ê·  ì ìˆ˜ ê³„ì‚°\n",
    "avg_psnr = np.mean(psnr_scores)\n",
    "avg_ssim = np.mean(ssim_scores)\n",
    "\n",
    "print(\"\\n===== í‰ê°€ ì™„ë£Œ =====\")\n",
    "print(f\"í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ í‰ê·  PSNR: {avg_psnr:.4f} dB\")\n",
    "print(f\"í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ í‰ê·  SSIM: {avg_ssim:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b40b82bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model] Multi-Branch AODNet ì´ˆê¸°í™” ì¤‘ (3 ë…ë¦½ K ë³€ìˆ˜ ëª¨ë“œ)...\n",
      "[Model] Multi-Branch AODNet ì´ˆê¸°í™” ì™„ë£Œ\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for AODnet_MultiBranch:\n\tUnexpected key(s) in state_dict: \"fusion_conv.weight\", \"fusion_conv.bias\". \n\tsize mismatch for k1_conv1.weight: copying a param with shape torch.Size([2, 3, 1, 1]) from checkpoint, the shape in current model is torch.Size([3, 3, 1, 1]).\n\tsize mismatch for k1_conv1.bias: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([3]).\n\tsize mismatch for k1_conv2.weight: copying a param with shape torch.Size([2, 2, 3, 3]) from checkpoint, the shape in current model is torch.Size([3, 3, 3, 3]).\n\tsize mismatch for k1_conv2.bias: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([3]).\n\tsize mismatch for k1_conv3.weight: copying a param with shape torch.Size([2, 4, 5, 5]) from checkpoint, the shape in current model is torch.Size([3, 6, 5, 5]).\n\tsize mismatch for k1_conv3.bias: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([3]).\n\tsize mismatch for k2_conv1.weight: copying a param with shape torch.Size([2, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([3, 3, 3, 3]).\n\tsize mismatch for k2_conv1.bias: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([3]).\n\tsize mismatch for k2_conv2.weight: copying a param with shape torch.Size([2, 2, 5, 5]) from checkpoint, the shape in current model is torch.Size([3, 3, 5, 5]).\n\tsize mismatch for k2_conv2.bias: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([3]).\n\tsize mismatch for k2_conv3.weight: copying a param with shape torch.Size([2, 4, 7, 7]) from checkpoint, the shape in current model is torch.Size([3, 6, 7, 7]).\n\tsize mismatch for k2_conv3.bias: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([3]).\n\tsize mismatch for k3_conv1.weight: copying a param with shape torch.Size([2, 3, 5, 5]) from checkpoint, the shape in current model is torch.Size([3, 3, 5, 5]).\n\tsize mismatch for k3_conv1.bias: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([3]).\n\tsize mismatch for k3_conv2.weight: copying a param with shape torch.Size([2, 2, 7, 7]) from checkpoint, the shape in current model is torch.Size([3, 3, 7, 7]).\n\tsize mismatch for k3_conv2.bias: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([3]).\n\tsize mismatch for k3_conv3.weight: copying a param with shape torch.Size([2, 4, 9, 9]) from checkpoint, the shape in current model is torch.Size([3, 6, 9, 9]).\n\tsize mismatch for k3_conv3.bias: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([3]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 28\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# ----------------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# ëª¨ë¸ êµ¬ì¡° ë¡œë“œ ë° ê°€ì¤‘ì¹˜ ë¶ˆëŸ¬ì˜¤ê¸°\u001b[39;00m\n\u001b[0;32m     27\u001b[0m evaluation_model \u001b[38;5;241m=\u001b[39m AODnet_MultiBranch()\u001b[38;5;241m.\u001b[39mto(DEVICE) \u001b[38;5;66;03m# DEVICEëŠ” ì´ì „ ì…€ì—ì„œ ì •ì˜ë¨\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m \u001b[43mevaluation_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODEL_WEIGHTS_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m evaluation_model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# ì´ë¯¸ì§€ ì „ì²˜ë¦¬ transform ì •ì˜\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:2593\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[0;32m   2585\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[0;32m   2586\u001b[0m             \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   2587\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2588\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[0;32m   2589\u001b[0m             ),\n\u001b[0;32m   2590\u001b[0m         )\n\u001b[0;32m   2592\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2593\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   2594\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2595\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)\n\u001b[0;32m   2596\u001b[0m         )\n\u001b[0;32m   2597\u001b[0m     )\n\u001b[0;32m   2598\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for AODnet_MultiBranch:\n\tUnexpected key(s) in state_dict: \"fusion_conv.weight\", \"fusion_conv.bias\". \n\tsize mismatch for k1_conv1.weight: copying a param with shape torch.Size([2, 3, 1, 1]) from checkpoint, the shape in current model is torch.Size([3, 3, 1, 1]).\n\tsize mismatch for k1_conv1.bias: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([3]).\n\tsize mismatch for k1_conv2.weight: copying a param with shape torch.Size([2, 2, 3, 3]) from checkpoint, the shape in current model is torch.Size([3, 3, 3, 3]).\n\tsize mismatch for k1_conv2.bias: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([3]).\n\tsize mismatch for k1_conv3.weight: copying a param with shape torch.Size([2, 4, 5, 5]) from checkpoint, the shape in current model is torch.Size([3, 6, 5, 5]).\n\tsize mismatch for k1_conv3.bias: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([3]).\n\tsize mismatch for k2_conv1.weight: copying a param with shape torch.Size([2, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([3, 3, 3, 3]).\n\tsize mismatch for k2_conv1.bias: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([3]).\n\tsize mismatch for k2_conv2.weight: copying a param with shape torch.Size([2, 2, 5, 5]) from checkpoint, the shape in current model is torch.Size([3, 3, 5, 5]).\n\tsize mismatch for k2_conv2.bias: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([3]).\n\tsize mismatch for k2_conv3.weight: copying a param with shape torch.Size([2, 4, 7, 7]) from checkpoint, the shape in current model is torch.Size([3, 6, 7, 7]).\n\tsize mismatch for k2_conv3.bias: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([3]).\n\tsize mismatch for k3_conv1.weight: copying a param with shape torch.Size([2, 3, 5, 5]) from checkpoint, the shape in current model is torch.Size([3, 3, 5, 5]).\n\tsize mismatch for k3_conv1.bias: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([3]).\n\tsize mismatch for k3_conv2.weight: copying a param with shape torch.Size([2, 2, 7, 7]) from checkpoint, the shape in current model is torch.Size([3, 3, 7, 7]).\n\tsize mismatch for k3_conv2.bias: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([3]).\n\tsize mismatch for k3_conv3.weight: copying a param with shape torch.Size([2, 4, 9, 9]) from checkpoint, the shape in current model is torch.Size([3, 6, 9, 9]).\n\tsize mismatch for k3_conv3.bias: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([3])."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import os\n",
    "\n",
    "# --- ì„¤ì • (â˜…â˜…â˜… ì‚¬ìš© ì „ ê¼­ ìˆ˜ì •í•´ì£¼ì„¸ìš” â˜…â˜…â˜…) ---\n",
    "# 1. ë¶ˆëŸ¬ì˜¬ í•™ìŠµëœ ëª¨ë¸ ê°€ì¤‘ì¹˜ íŒŒì¼ì˜ ê²½ë¡œ\n",
    "MODEL_WEIGHTS_PATH = \"pt/TBaodNet5/best_model_epoch_100.pth\"\n",
    "\n",
    "# 2. ë³µì›í•  ì•ˆê°œ ì´ë¯¸ì§€(input) íŒŒì¼ ê²½ë¡œë“¤ì„ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ì§€ì •\n",
    "HAZY_IMAGE_PATHS = [\n",
    "    \"dataset_split/test/input/51_rain.png\",\n",
    "    \"dataset_split/test/input/im_0048_s95_a06.png\",\n",
    "    \"dataset_split/test/input/NYU2_1331.jpg\"\n",
    "]\n",
    "\n",
    "# 3. ì •ë‹µ ì´ë¯¸ì§€(gt)ê°€ ë“¤ì–´ìˆëŠ” í´ë” ê²½ë¡œ\n",
    "GT_BASE_DIR = \"dataset_split/test/gt\"\n",
    "\n",
    "# 4. ëª¨ë¸ í•™ìŠµ ì‹œ ì‚¬ìš©í–ˆë˜ ì´ë¯¸ì§€ í•´ìƒë„\n",
    "TARGET_IMAGE_SIZE = (240, 360)\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "# ëª¨ë¸ êµ¬ì¡° ë¡œë“œ ë° ê°€ì¤‘ì¹˜ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "evaluation_model = AODnet_MultiBranch().to(DEVICE) # DEVICEëŠ” ì´ì „ ì…€ì—ì„œ ì •ì˜ë¨\n",
    "evaluation_model.load_state_dict(torch.load(MODEL_WEIGHTS_PATH, map_location=DEVICE))\n",
    "evaluation_model.eval()\n",
    "\n",
    "# ì´ë¯¸ì§€ ì „ì²˜ë¦¬ transform ì •ì˜\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(TARGET_IMAGE_SIZE),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# ê²°ê³¼ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
    "hazy_images_pil = []\n",
    "restored_images_pil = []\n",
    "clean_images_pil = []\n",
    "\n",
    "print(\"ì´ë¯¸ì§€ ë³µì›ì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "\n",
    "for hazy_path in HAZY_IMAGE_PATHS:\n",
    "    try:\n",
    "        filename = os.path.basename(hazy_path)\n",
    "        \n",
    "        # â˜…â˜…â˜… ìˆ˜ì •ëœ ë¶€ë¶„ â˜…â˜…â˜…\n",
    "        # os.path.joinìœ¼ë¡œ ìƒì„±ëœ ê²½ë¡œë¥¼ os.path.normpathë¡œ ì •ê·œí™”\n",
    "        clean_path_raw = os.path.join(GT_BASE_DIR, filename)\n",
    "        clean_path = os.path.normpath(clean_path_raw)\n",
    "        \n",
    "        if not os.path.exists(clean_path):\n",
    "            print(f\"ê²½ê³ : ì§ì´ ë˜ëŠ” ì •ë‹µ ì´ë¯¸ì§€ '{clean_path}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
    "            continue\n",
    "\n",
    "        hazy_image = Image.open(hazy_path).convert('RGB')\n",
    "        clean_image = Image.open(clean_path).convert('RGB')\n",
    "        \n",
    "        hazy_tensor = transform(hazy_image).unsqueeze(0).to(DEVICE)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            restored_tensor = evaluation_model(hazy_tensor)\n",
    "\n",
    "        restored_image = transforms.ToPILImage()(restored_tensor.squeeze(0).cpu())\n",
    "\n",
    "        hazy_images_pil.append(hazy_image)\n",
    "        restored_images_pil.append(restored_image)\n",
    "        clean_images_pil.append(clean_image)\n",
    "        print(f\"'{hazy_path}' ë³µì› ë° ì •ë‹µ ì´ë¯¸ì§€ ë¡œë“œ ì™„ë£Œ.\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ì˜¤ë¥˜: '{hazy_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
    "    except Exception as e:\n",
    "        print(f\"'{hazy_path}' ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "\n",
    "# --- ì‹œê°í™” ë¶€ë¶„ ---\n",
    "if hazy_images_pil:\n",
    "    num_images = len(hazy_images_pil)\n",
    "    # 3ê°œì˜ í–‰(ì´ë¯¸ì§€ ìŒ), 3ê°œì˜ ì—´(Input, Restored, GT)\n",
    "    plt.figure(figsize=(18, 5 * num_images)) \n",
    "\n",
    "    for i in range(num_images):\n",
    "        # --- ië²ˆì§¸ ì´ë¯¸ì§€ ìŒ ---\n",
    "        \n",
    "        # 1ì—´: ì…ë ¥(Hazy) ì´ë¯¸ì§€\n",
    "        plt.subplot(num_images, 3, i * 3 + 1)\n",
    "        plt.imshow(hazy_images_pil[i])\n",
    "        plt.title(f'Input (Hazy) #{i+1}')\n",
    "        plt.axis('off')\n",
    "\n",
    "        # 2ì—´: ë³µì›ëœ ì´ë¯¸ì§€\n",
    "        plt.subplot(num_images, 3, i * 3 + 2)\n",
    "        plt.imshow(restored_images_pil[i])\n",
    "        plt.title(f'Restored #{i+1}')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # 3ì—´: ì •ë‹µ(GT) ì´ë¯¸ì§€\n",
    "        plt.subplot(num_images, 3, i * 3 + 3)\n",
    "        plt.imshow(clean_images_pil[i])\n",
    "        plt.title(f'Ground Truth #{i+1}')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(\"\\nì´ë¯¸ì§€ ë³µì› ë° ë¹„êµ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb6ee873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model] ê²½ëŸ‰í™”ëœ Multi-Branch AODNet (ì±„ë„ ì¶•ì†Œ) ì´ˆê¸°í™” ì¤‘...\n",
      "[Model] ê²½ëŸ‰í™” ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ\n",
      "\n",
      "ëª¨ë¸ì´ aodnet5.onnx íŒŒì¼ë¡œ ì„±ê³µì ìœ¼ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# onnx ë³€í™˜ìš© ì…€\n",
    "# pth_to_onnx.py\n",
    "import torch\n",
    "\n",
    "# 1. ëª¨ë¸ êµ¬ì¡° ë¶ˆëŸ¬ì˜¤ê¸° ë° ê°€ì¤‘ì¹˜ ë¡œë“œ\n",
    "model = AODnet_MultiBranch_Light()\n",
    "model.load_state_dict(torch.load('./pt/TBaodNet5/best_model_epoch_100.pth', map_location='cpu'))\n",
    "model.eval() # ë°˜ë“œì‹œ evaluation ëª¨ë“œë¡œ ì„¤ì •!\n",
    "\n",
    "# 2. ëª¨ë¸ì— ì…ë ¥ë  ë”ë¯¸ ë°ì´í„° ìƒì„± (ì¤‘ìš”!)\n",
    "# ëª¨ë¸ì´ í•™ìŠµí•  ë•Œ ì‚¬ìš©í•œ ì´ë¯¸ì§€ í¬ê¸°ì™€ ë™ì¼í•˜ê²Œ ë§ì¶°ì£¼ì„¸ìš”.\n",
    "# ì˜ˆ: (ë°°ì¹˜í¬ê¸°, ì±„ë„, ë†’ì´, ë„ˆë¹„)\n",
    "dummy_input = torch.randn(1, 3, 240, 360) \n",
    "\n",
    "# 3. ONNX íŒŒì¼ë¡œ ë³€í™˜\n",
    "onnx_file_path = \"aodnet5.onnx\"\n",
    "torch.onnx.export(model,\n",
    "                  dummy_input,\n",
    "                  onnx_file_path,\n",
    "                  export_params=True,\n",
    "                  opset_version=11, # í˜¸í™˜ì„±ì„ ìœ„í•´ ë²„ì „ì„ ëª…ì‹œí•˜ëŠ” ê²ƒì´ ì¢‹ìŒ\n",
    "                  do_constant_folding=True,\n",
    "                  input_names = ['input'],\n",
    "                  output_names = ['output'])\n",
    "\n",
    "print(f\"ëª¨ë¸ì´ {onnx_file_path} íŒŒì¼ë¡œ ì„±ê³µì ìœ¼ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee41c9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\zmffk\\OneDrive\\ë°”íƒ• í™”ë©´\\model\\new-tf-env\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\zmffk\\OneDrive\\ë°”íƒ• í™”ë©´\\model\\new-tf-env\\lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.logging.TaskLevelStatusMessage is deprecated. Please use tf.compat.v1.logging.TaskLevelStatusMessage instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\zmffk\\OneDrive\\ë°”íƒ• í™”ë©´\\model\\new-tf-env\\lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.control_flow_v2_enabled is deprecated. Please use tf.compat.v1.control_flow_v2_enabled instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zmffk\\OneDrive\\ë°”íƒ• í™”ë©´\\model\\new-tf-env\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\zmffk\\OneDrive\\ë°”íƒ• í™”ë©´\\model\\new-tf-env\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.12.0 and strictly below 2.15.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.15.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX ëª¨ë¸ì„ TensorFlow SavedModelë¡œ ë³€í™˜í•˜ëŠ” ì¤‘...\n",
      "INFO:tensorflow:Assets written to: C:/temp/aodnet_tf_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/temp/aodnet_tf_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ëª¨ë¸ì´ 'C:/temp/aodnet_tf_model' í´ë”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "TFLite ë³€í™˜ ë° ì •ìˆ˜ ì–‘ìí™” ì‹œì‘...\n",
      "ëŒ€í‘œ ë°ì´í„°ì…‹ ìƒì„± ì¤‘...\n",
      "ëŒ€í‘œ ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ.\n",
      "--------------------------------------------------\n",
      "âœ… ì •ìˆ˜ ì–‘ìí™”ëœ ëª¨ë¸ 'aodnet5_quant_int8.tflite'ì´ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "ì´ íŒŒì¼ì„ ë¼ì¦ˆë² ë¦¬íŒŒì´ë¡œ ì˜®ê²¨ì„œ í…ŒìŠ¤íŠ¸í•˜ì„¸ìš”!\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# TFLite ë³€í™˜ìš© ì…€\n",
    "\n",
    "# 1. í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ (ìµœì´ˆ 1íšŒë§Œ ì‹¤í–‰)\n",
    "# !pip install onnx onnx-tf tensorflow\n",
    "\n",
    "import tensorflow as tf\n",
    "import onnx\n",
    "from onnx_tf.backend import prepare\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# --- ì„¤ì • ---\n",
    "onnx_file_path = \"aodnet5.onnx\"\n",
    "saved_model_dir = \"C:/temp/aodnet_tf_model\"\n",
    "quantized_tflite_path = \"aodnet5_quant_int8.tflite\"\n",
    "\n",
    "\n",
    "# 2. ONNX ëª¨ë¸ì„ TensorFlow SavedModel í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (TFLite ë³€í™˜ì„ ìœ„í•œ ì¤‘ê°„ ë‹¨ê³„)\n",
    "print(\"ONNX ëª¨ë¸ì„ TensorFlow SavedModelë¡œ ë³€í™˜í•˜ëŠ” ì¤‘...\")\n",
    "onnx_model = onnx.load(onnx_file_path)\n",
    "tf_rep = prepare(onnx_model)\n",
    "tf_rep.export_graph(saved_model_dir)\n",
    "print(f\"ëª¨ë¸ì´ '{saved_model_dir}' í´ë”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "\n",
    "# 3. ëŒ€í‘œ ë°ì´í„°ì…‹ ì¤€ë¹„ (ê°€ì¥ ì¤‘ìš”!)\n",
    "# ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ë¥¼ float32ì—ì„œ int8ë¡œ ë³€í™˜í•  ë•Œ, ì–´ë–¤ ê°’ ë²”ìœ„ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì‚¼ì„ì§€ ì•Œë ¤ì£¼ëŠ” ìƒ˜í”Œ ë°ì´í„°ì…ë‹ˆë‹¤.\n",
    "# ì‹¤ì œ ëª¨ë¸ì— ì…ë ¥ë  ì´ë¯¸ì§€ì™€ ìœ ì‚¬í•œ ë°ì´í„° 100~200ê°œë¥¼ ì‚¬ìš©í•˜ë©´ ì •í™•ë„ê°€ ë†’ì•„ì§‘ë‹ˆë‹¤.\n",
    "def representative_data_gen():\n",
    "  print(\"ëŒ€í‘œ ë°ì´í„°ì…‹ ìƒì„± ì¤‘...\")\n",
    "  # ì°¸ê³ : ì—¬ê¸°ì„œëŠ” ëœë¤ ë°ì´í„°ë¥¼ ìƒì„±í–ˆì§€ë§Œ, ì‹¤ì œë¡œëŠ” í•™ìŠµì— ì‚¬ìš©í–ˆë˜ ë°ì´í„°ë‚˜\n",
    "  # ë¼ì¦ˆë² ë¦¬íŒŒì´ì—ì„œ ì´¬ì˜ë  ì´ë¯¸ì§€ì™€ ë¹„ìŠ·í•œ ìƒ˜í”Œ ì´ë¯¸ì§€ë“¤ì„ ì „ì²˜ë¦¬í•´ì„œ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "  for _ in range(100):\n",
    "    # PyTorch ëª¨ë¸ì˜ ì…ë ¥ í˜•ì‹ê³¼ ë™ì¼í•˜ê²Œ (ë°°ì¹˜, ì±„ë„, ë†’ì´, ë„ˆë¹„) ìˆœì„œë¡œ ìƒì„±\n",
    "    dummy_input = np.random.rand(1, 3, 240, 360).astype(np.float32)\n",
    "    yield [dummy_input]\n",
    "  print(\"ëŒ€í‘œ ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ.\")\n",
    "\n",
    "\n",
    "# 4. TFLite ë³€í™˜ê¸° ì„¤ì • ë° ì •ìˆ˜ ì–‘ìí™”\n",
    "print(\"TFLite ë³€í™˜ ë° ì •ìˆ˜ ì–‘ìí™” ì‹œì‘...\")\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "\n",
    "# ëª¨ë“  ì—°ì‚°ì„ INT8ë¡œ ê°•ì œí•˜ì—¬ ìµœëŒ€ ì„±ëŠ¥ í™•ë³´ (í˜¸í™˜ì„± ë¬¸ì œê°€ ë°œìƒí•˜ë©´ ì´ ì¤„ì„ ì£¼ì„ ì²˜ë¦¬)\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "\n",
    "# 5. ëª¨ë¸ ë³€í™˜ ë° ì €ì¥\n",
    "tflite_quant_model = converter.convert()\n",
    "\n",
    "with open(quantized_tflite_path, 'wb') as f:\n",
    "  f.write(tflite_quant_model)\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(f\"âœ… ì •ìˆ˜ ì–‘ìí™”ëœ ëª¨ë¸ '{quantized_tflite_path}'ì´ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "print(f\"ì´ íŒŒì¼ì„ ë¼ì¦ˆë² ë¦¬íŒŒì´ë¡œ ì˜®ê²¨ì„œ í…ŒìŠ¤íŠ¸í•˜ì„¸ìš”!\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a783255",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python3\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from picamera2 import Picamera2\n",
    "from tensorflow.lite.python.interpreter import Interpreter\n",
    "\n",
    "# --- ì„¤ì • ---\n",
    "MODEL_PATH = 'aodnet5_quant_int8.tflite'\n",
    "# â˜… ëª¨ë¸ì˜ ì…ë ¥ í¬ê¸°ì— ë§ê²Œ ë„ˆë¹„(WIDTH)ì™€ ë†’ì´(HEIGHT) ìˆœì„œë¥¼ í™•ì¸í•˜ê³  ìˆ˜ì •í•©ë‹ˆë‹¤.\n",
    "# ëª¨ë¸ ì…ë ¥ì´ (1, 3, 240, 360) ì´ë¯€ë¡œ ë†’ì´(H)=240, ë„ˆë¹„(W)=360 ì…ë‹ˆë‹¤.\n",
    "WIDTH, HEIGHT = 360, 240\n",
    "\n",
    "def main():\n",
    "    # --- 1. TFLite ëª¨ë¸ ë¡œë“œ ---\n",
    "    try:\n",
    "        interpreter = Interpreter(model_path=MODEL_PATH, num_threads=4)\n",
    "        interpreter.allocate_tensors()\n",
    "        \n",
    "        input_details = interpreter.get_input_details()\n",
    "        output_details = interpreter.get_output_details()\n",
    "        \n",
    "        model_input_shape = input_details[0]['shape']\n",
    "        print(f\"ëª¨ë¸ì´ ìš”êµ¬í•˜ëŠ” ì‹¤ì œ ì…ë ¥ í˜•íƒœ: {model_input_shape}\")\n",
    "\n",
    "        # â­ï¸ ëª¨ë¸ì˜ ì…ë ¥ ë°ì´í„° íƒ€ì…ì´ INT8ì¸ì§€ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "        is_int8_model = (input_details[0]['dtype'] == np.int8)\n",
    "        \n",
    "        if is_int8_model:\n",
    "            print(\"INFO: ëª¨ë¸ì´ int8 ì…ë ¥ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ì •ìˆ˜í˜•ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\")\n",
    "            # â­ï¸ INT8 ë³€í™˜ì— í•„ìš”í•œ ìŠ¤ì¼€ì¼ê³¼ ì œë¡œ í¬ì¸íŠ¸ë¥¼ ë¯¸ë¦¬ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "            input_quant_params = input_details[0]['quantization_parameters']\n",
    "            input_scale = input_quant_params['scales'][0]\n",
    "            input_zero_point = input_quant_params['zero_points'][0]\n",
    "            \n",
    "            output_quant_params = output_details[0]['quantization_parameters']\n",
    "            output_scale = output_quant_params['scales'][0]\n",
    "            output_zero_point = output_quant_params['zero_points'][0]\n",
    "        else:\n",
    "            print(\"INFO: ëª¨ë¸ì´ float32 ì…ë ¥ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ì‹¤ìˆ˜í˜•ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ëª¨ë¸ ë¡œë”©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}\")\n",
    "        return\n",
    "\n",
    "    # --- 2. ì¹´ë©”ë¼ ì„¤ì • ---\n",
    "    picam2 = Picamera2()\n",
    "    config = picam2.create_preview_configuration(\n",
    "        main={\"size\": (WIDTH, HEIGHT), \"format\": \"RGB888\"}\n",
    "    )\n",
    "    picam2.configure(config)\n",
    "    picam2.start()\n",
    "    time.sleep(1)\n",
    "    print(\"ì¹´ë©”ë¼ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    fps_counter = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            frame_original = picam2.capture_array()\n",
    "            # í”„ë ˆì„ íšŒì „ì´ í•„ìš”í•˜ë‹¤ë©´ ì•„ë˜ ì½”ë“œì˜ ì£¼ì„ì„ í•´ì œí•˜ì„¸ìš”.\n",
    "            frame = cv2.rotate(frame_original, cv2.ROTATE_180) \n",
    "            # frame = frame_original # íšŒì „ì´ í•„ìš” ì—†ë‹¤ë©´ ì´ ì¤„ì„ ì‚¬ìš©\n",
    "\n",
    "            # --- 3. ì…ë ¥ ë°ì´í„° ì „ì²˜ë¦¬ ---\n",
    "            # ëª¨ë¸ì˜ ì…ë ¥ í˜•íƒœ (1, C, H, W)ì—ì„œ ë†’ì´ì™€ ë„ˆë¹„ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "            _, _, model_height, model_width = model_input_shape\n",
    "            input_image = cv2.resize(frame, (model_width, model_height))\n",
    "            \n",
    "            # ë°°ì¹˜ ì°¨ì› ì¶”ê°€ (H, W, C) -> (1, H, W, C)\n",
    "            input_data = np.expand_dims(input_image, axis=0)\n",
    "            \n",
    "            # â­ï¸ INT8 ëª¨ë¸ì„ ìœ„í•œ ë°ì´í„° ì–‘ìí™” (ê°€ì¥ ì¤‘ìš”í•œ ë¶€ë¶„)\n",
    "            if is_int8_model:\n",
    "                # uint8 (0~255) -> float32 (0.0~1.0)\n",
    "                input_data_float = input_data.astype(np.float32) / 255.0\n",
    "                # float32 (0.0~1.0) -> int8 (-128~127)\n",
    "                input_data = (input_data_float / input_scale + input_zero_point).astype(np.int8)\n",
    "            else: # float32 ëª¨ë¸ì˜ ê²½ìš°\n",
    "                input_data = (input_data.astype(np.float32) / 255.0)\n",
    "\n",
    "            # TensorFlow(NHWC) -> ONNX/PyTorch(NCHW) ìˆœì„œë¡œ ë³€ê²½\n",
    "            # (1, H, W, C) -> (1, C, H, W)\n",
    "            input_data = np.transpose(input_data, (0, 3, 1, 2))\n",
    "\n",
    "            # --- 4. ëª¨ë¸ ì¶”ë¡  ---\n",
    "            interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "            interpreter.invoke()\n",
    "            output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "            # --- 5. ì¶œë ¥ ë°ì´í„° í›„ì²˜ë¦¬ ---\n",
    "            # ONNX/PyTorch(NCHW) -> TensorFlow(NHWC) ìˆœì„œë¡œ ë³€ê²½\n",
    "            # (1, C, H, W) -> (1, H, W, C)\n",
    "            output_data_nhwc = np.transpose(output_data, (0, 2, 3, 1))\n",
    "            \n",
    "            # â­ï¸ INT8 ëª¨ë¸ì˜ ì¶œë ¥ê°’ì„ ì´ë¯¸ì§€ë¡œ ë³€í™˜ (ì—­ì–‘ìí™”)\n",
    "            if is_int8_model:\n",
    "                # int8 (-128~127) -> float32 (0.0~1.0)\n",
    "                output_data_float = (output_data_nhwc.astype(np.float32) - output_zero_point) * output_scale\n",
    "                # float32 -> uint8 (0~255)\n",
    "                processed_image = np.clip(output_data_float[0] * 255.0, 0, 255).astype(np.uint8)\n",
    "            else: # float32 ëª¨ë¸ì˜ ê²½ìš°\n",
    "                processed_image = (output_data_nhwc[0] * 255.0).astype(np.uint8)\n",
    "            \n",
    "            # --- 6. ê²°ê³¼ ì¶œë ¥ ---\n",
    "            processed_bgr = cv2.cvtColor(processed_image, cv2.COLOR_RGB2BGR)\n",
    "            cv2.imshow('Processed by TFLite', processed_bgr)\n",
    "\n",
    "            fps_counter += 1\n",
    "            if time.time() - start_time >= 1:\n",
    "                print(f\"FPS: {fps_counter}\")\n",
    "                fps_counter = 0\n",
    "                start_time = time.time()\n",
    "            \n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "    \n",
    "    finally:\n",
    "        print(\"í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
    "        picam2.stop()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
