import torch
import cv2
import numpy as np
import os
from skimage.metrics import peak_signal_noise_ratio as calculate_psnr
from skimage.metrics import structural_similarity as calculate_ssim
import model.lightmodel as lightmodel

def load_trained_model(path, device):
    """
    - íŒŒì¼ í™•ì¥ìê°€ '.pt'ì´ë©´ torch.jit.load()ë¥¼ ì‹œë„
    - ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ torch.load()ë¡œ state_dictë¥¼ ë¶ˆëŸ¬ì™€ ì§ì ‘ ë¡œë“œ
    """
    extension = os.path.splitext(path)[1].lower()
    if extension == ".pt":
        print(f"[Load] TorchScript ì•„ì¹´ì´ë¸Œ '{path}' ë¡œë“œ ì¤‘...")
        model = torch.jit.load(path, map_location=device)
        model.to(device)
        model.eval()
        print("[Load] TorchScript ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (eval ëª¨ë“œ).\n")
        return model

    else:
        print(f"[Load] state_dict ì•„ì¹´ì´ë¸Œ '{path}' ë¡œë“œ ì¤‘...")
        model = lightmodel.DerainNetLite().to(device)
        checkpoint = torch.load(path, map_location=device)

        if isinstance(checkpoint, dict) and "model_state_dict" in checkpoint:
            state_dict = checkpoint["model_state_dict"]
        else:
            state_dict = checkpoint

        model.load_state_dict(state_dict)
        model.eval()
        print("[Load] state_dict ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (eval ëª¨ë“œ).\n")
        return model

if __name__ == "__main__":
    print("===== ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸ ì‹œì‘ =====")

    # (1) device ì„¤ì •
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"[Config] Using device: {device}")

    # (2) ê²½ë¡œ ì„¤ì •
    trained_path = "./pt/Litemodel.pt"
    sample_rain_img = "./dataset_split/val/input/8_rain.png"
    gt_clean_img = "./dataset_split/val/gt/8_rain.png"  # ğŸ‘ˆ [ìˆ˜ì •] ì •ë‹µ(Ground Truth) ì´ë¯¸ì§€ ê²½ë¡œ ì¶”ê°€
    output_path = "./processedImg/processed_image2.jpg"
    
    # ëª¨ë¸ ë¡œë“œ
    model = load_trained_model(trained_path, device)

    # (3) ì¶”ë¡ í•  ì´ë¯¸ì§€ ë° ì •ë‹µ ì´ë¯¸ì§€ ë¶ˆëŸ¬ì˜¤ê¸°
    print(f"[Inference] ì²˜ë¦¬í•  ì´ë¯¸ì§€: {sample_rain_img}")
    print(f"[Evaluation] ì •ë‹µ ì´ë¯¸ì§€: {gt_clean_img}") # ğŸ‘ˆ [ì¶”ê°€]

    # (4-1) ì…ë ¥ ì´ë¯¸ì§€(ë¹„ ì˜¤ëŠ”) ì—´ê¸° ë° ì „ì²˜ë¦¬
    img_bgr = cv2.imread(sample_rain_img)
    if img_bgr is None:
        raise FileNotFoundError(f"ì…ë ¥ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {sample_rain_img}")
    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)

    H, W = 480, 720  # ëª¨ë¸ ì…ë ¥ í¬ê¸° (height, width)
    img_resized = cv2.resize(img_rgb, (W, H))
    img_f = img_resized.astype(np.float32) / 255.0
    
    # ğŸ‘ˆ [ì¶”ê°€] (4-2) ì •ë‹µ ì´ë¯¸ì§€(ê¹¨ë—í•œ) ì—´ê¸° ë° ì „ì²˜ë¦¬
    gt_bgr = cv2.imread(gt_clean_img)
    if gt_bgr is None:
        raise FileNotFoundError(f"ì •ë‹µ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {gt_clean_img}")
    gt_rgb = cv2.cvtColor(gt_bgr, cv2.COLOR_BGR2RGB)
    gt_resized = cv2.resize(gt_rgb, (W, H)) # ì…ë ¥ê³¼ ë™ì¼í•œ í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
    gt_f = gt_resized.astype(np.float32) / 255.0

    # ëª¨ë¸ ì¶”ë¡ 
    input_tensor = torch.from_numpy(img_f).permute(2, 0, 1).unsqueeze(0).to(device)
    with torch.no_grad():
        output_tensor = model(input_tensor)

    # ì¶œë ¥ í…ì„œë¥¼ ì´ë¯¸ì§€ í˜•íƒœë¡œ ë³€í™˜
    output_img_f = output_tensor.squeeze(0).permute(1, 2, 0).cpu().numpy()
    output_img_f = np.clip(output_img_f, 0.0, 1.0)

    # --- SSIM ë° PSNR ê³„ì‚° ì½”ë“œ (ìˆ˜ì •ë¨) ---

    # ì •ë‹µ ì´ë¯¸ì§€ (0~1 ë²”ìœ„ float32)
    gt_img_for_metrics = gt_f  # ğŸ‘ˆ [ìˆ˜ì •] 'original_img'ê°€ ì•„ë‹Œ 'gt_img' ì‚¬ìš©

    # ì²˜ë¦¬ëœ ì´ë¯¸ì§€ (0~1 ë²”ìœ„ float32)
    processed_img_for_metrics = output_img_f

    # PSNR ê³„ì‚° (ì •ë‹µ ì´ë¯¸ì§€ì™€ ëª¨ë¸ ì¶œë ¥ ë¹„êµ)
    psnr_value = calculate_psnr(gt_img_for_metrics, processed_img_for_metrics, data_range=1.0)
    print(f"ê³„ì‚°ëœ PSNR: {psnr_value:.4f}")

    # SSIM ê³„ì‚° (ì •ë‹µ ì´ë¯¸ì§€ì™€ ëª¨ë¸ ì¶œë ¥ ë¹„êµ)
    ssim_value = calculate_ssim(gt_img_for_metrics, processed_img_for_metrics, data_range=1.0, channel_axis=2)
    print(f"ê³„ì‚°ëœ SSIM: {ssim_value:.4f}")

    # --- ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥ ---
    output_img_uint8 = (output_img_f * 255).astype(np.uint8)
    output_img_bgr = cv2.cvtColor(output_img_uint8, cv2.COLOR_RGB2BGR)
    
    cv2.imwrite(output_path, output_img_bgr)
    print(f"ì²˜ë¦¬ëœ ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {output_path}")

    print("===== ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸ ì¢…ë£Œ =====")